{"cells":[{"cell_type":"code","execution_count":null,"id":"70d78901","metadata":{"id":"70d78901","outputId":"075696ac-3851-458e-f893-cf8ee1b88dda"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package gutenberg to C:\\Users\\Sirotul\n","[nltk_data]     Azhar\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import nltk\n","import nltk.corpus\n","\n","nltk.download('gutenberg')"]},{"cell_type":"code","execution_count":null,"id":"405da15e","metadata":{"id":"405da15e","outputId":"17274f94-fc59-4b6b-f13a-6bd0caf5ab84"},"outputs":[{"name":"stdout","output_type":"stream","text":["['gutenberg', 'gutenberg.zip', 'stopwords', 'stopwords.zip']\n"]}],"source":["print(os.listdir(nltk.data.find(\"corpora\")))"]},{"cell_type":"code","execution_count":null,"id":"40920169","metadata":{"id":"40920169","outputId":"344b6643-f9b1-4dd3-80f7-c3b93f046316"},"outputs":[{"data":{"text/plain":["['austen-emma.txt',\n"," 'austen-persuasion.txt',\n"," 'austen-sense.txt',\n"," 'bible-kjv.txt',\n"," 'blake-poems.txt',\n"," 'bryant-stories.txt',\n"," 'burgess-busterbrown.txt',\n"," 'carroll-alice.txt',\n"," 'chesterton-ball.txt',\n"," 'chesterton-brown.txt',\n"," 'chesterton-thursday.txt',\n"," 'edgeworth-parents.txt',\n"," 'melville-moby_dick.txt',\n"," 'milton-paradise.txt',\n"," 'shakespeare-caesar.txt',\n"," 'shakespeare-hamlet.txt',\n"," 'shakespeare-macbeth.txt',\n"," 'whitman-leaves.txt']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["nltk.corpus.gutenberg.fileids()"]},{"cell_type":"code","execution_count":null,"id":"5909ba0d","metadata":{"id":"5909ba0d","outputId":"cfffb6b2-ba4b-47a2-b493-3abb40b3414e"},"outputs":[{"name":"stdout","output_type":"stream","text":["['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]\n"]}],"source":["hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n","print(hamlet)"]},{"cell_type":"code","execution_count":null,"id":"293d62a1","metadata":{"id":"293d62a1","outputId":"9c6b0359-ee8a-4309-d119-7ab7b102f680"},"outputs":[{"name":"stdout","output_type":"stream","text":["[TheTragedieofHamletbyWilliamShakespeare1599]ActusPrimus.ScoenaPrima.EnterBarnardoandFranciscotwoCentinels.Barnardo.Who'sthere?Fran.Nayanswerme:Stand&vnfoldyourselfeBar.LongliuetheKingFran.Barnardo?Bar.HeFran.YoucomemostcarefullyvponyourhoureBar.'Tisnowstrooktwelue,gettheetobedFranciscoFran.Forthisreleefemuchthankes:'Tisbittercold,AndIamsickeatheartBarn.HaueyouhadquietGuard?Fran.NotaMousestirringBarn.Well,goodnight.IfyoudomeetHoratioandMarcellus,theRiualsofmyWatch,bidthemmakehast.EnterHoratioandMarcellus.Fran.IthinkeIhearethem.Stand:who'sthere?Hor.FriendstothisgroundMar.AndLeige-mentotheDaneFran.GiueyougoodnightMar.OfarwelhonestSoldier,whohathrelieu'dyou?Fra.Barnardoha'smyplace:giueyougoodnight.ExitFran.Mar.HollaBarnardoBar.Say,whatisHoratiothere?Hor.ApeeceofhimBar.WelcomeHoratio,welcomegoodMarcellusMar.What,ha'sthisthingappear'dagainetonightBar.IhaueseenenothingMar.Horatiosaies,'tisbutourFantasie,AndwillnotletbeleefetakeholdofhimTouchingthisdreadedsight,twiceseeneofvs,ThereforeIhaueintreatedhimalongWithvs,towatchtheminutesofthisNight,ThatifagainethisApparitioncome,Hemayapproueoureyes,andspeaketoitHor.Tush,tush,'twillnotappeareBar.Sitdownea-while,Andletvsonceagaineassaileyoureares,ThataresofortifiedagainstourStory,WhatwetwoNightshaueseeneHor.Well,sitwedowne,AndletvsheareBarnardospeakeofthisBarn.Lastnightofall,WhenyondsameStarrethat'sWestwardfromthePoleHadmadehiscourset'illumethatpartofHeauenWherenowitburnes,Marcellusandmyselfe,TheBellthenbeatingoneMar.Peace,breaketheeof:EntertheGhost.LookewhereitcomesagaineBarn.Inthesamefigure,liketheKingthat'sdeadMar.ThouartaScholler;speaketoitHoratioBarn.LookesitnotliketheKing?MarkeitHoratioHora.Mostlike:Itharrowesmewithfear&wonderBarn.ItwouldbespoketooMar.QuestionitHoratioHor.Whatart"]}],"source":["for word in hamlet[:500]:\n","    print(word, sep= '', end= '')"]},{"cell_type":"code","execution_count":null,"id":"87d842bd","metadata":{"id":"87d842bd"},"outputs":[],"source":["AI= \"\"\" You and everyone you know are going to be dead soon. And in the short amount of time between here and there, you have a limited amount of fucks to give. Very few, in fact. And if you go around giving a fuck about everything and everyone without conscious thought or choice—well, then you’re going to get fucked.\"\"\""]},{"cell_type":"code","execution_count":null,"id":"12d37eca","metadata":{"id":"12d37eca","outputId":"89f7f29e-4d67-417e-acd7-d64e23577559"},"outputs":[{"data":{"text/plain":["str"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["type(AI)"]},{"cell_type":"code","execution_count":null,"id":"10392f8c","metadata":{"id":"10392f8c","outputId":"e03843cd-1f0b-4b19-b015-14cf1473eae3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['You', 'and', 'everyone', 'you', 'know', 'are', 'going', 'to', 'be', 'dead', 'soon', '.', 'And', 'in', 'the', 'short', 'amount', 'of', 'time', 'between', 'here', 'and', 'there', ',', 'you', 'have', 'a', 'limited', 'amount', 'of', 'fucks', 'to', 'give', '.', 'Very', 'few', ',', 'in', 'fact', '.', 'And', 'if', 'you', 'go', 'around', 'giving', 'a', 'fuck', 'about', 'everything', 'and', 'everyone', 'without', 'conscious', 'thought', 'or', 'choice—well', ',', 'then', 'you', '’', 're', 'going', 'to', 'get', 'fucked', '.']\n"]}],"source":["from nltk import word_tokenize\n","\n","AI_tokens = word_tokenize(AI)\n","print(AI_tokens)"]},{"cell_type":"code","execution_count":null,"id":"4a1db0c0","metadata":{"id":"4a1db0c0","outputId":"2e53a455-c649-4105-a3dc-77e50039c982"},"outputs":[{"name":"stdout","output_type":"stream","text":["<FreqDist with 46 samples and 67 outcomes>\n"]},{"data":{"text/plain":["[('you', 5),\n"," ('and', 5),\n"," ('.', 4),\n"," ('to', 3),\n"," (',', 3),\n"," ('everyone', 2),\n"," ('going', 2),\n"," ('in', 2),\n"," ('amount', 2),\n"," ('of', 2),\n"," ('a', 2),\n"," ('know', 1),\n"," ('are', 1),\n"," ('be', 1),\n"," ('dead', 1),\n"," ('soon', 1),\n"," ('the', 1),\n"," ('short', 1),\n"," ('time', 1),\n"," ('between', 1)]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.probability import FreqDist\n","fdist = FreqDist()\n","for word in AI_tokens:\n","    fdist[word.lower()]+=1\n","print(fdist)\n","fdist_top10=fdist.most_common(20)\n","fdist_top10"]},{"cell_type":"code","execution_count":null,"id":"85f666fd","metadata":{"id":"85f666fd","outputId":"1ba7c275-8f3a-4da9-a800-810abac88fca"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.tokenize import blankline_tokenize\n","\n","AI_blank = blankline_tokenize (AI)\n","len(AI_blank)"]},{"cell_type":"code","execution_count":null,"id":"b65dbd33","metadata":{"id":"b65dbd33"},"outputs":[],"source":["from nltk.util import bigrams, trigrams, ngrams\n","\n","string = \"The best and most beautiful things in the world cannot be seen or even touched, they must be felt with heart\"\n","quotes_tokens = nltk.word_tokenize(string)\n","quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n","quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n","quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))"]},{"cell_type":"code","execution_count":null,"id":"aced500b","metadata":{"id":"aced500b","outputId":"5b2ec80c-deef-441b-ec1e-c62a50e42f1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["give: give\n","giving: give\n","gave: gave\n"]}],"source":["from nltk.stem import PorterStemmer\n","\n","pst = PorterStemmer()\n","pst.stem(\"having\")\n","words_to_stem = [\"give\", \"giving\", \"gave\"]\n","for words in words_to_stem:\n","    print(words+ \": \" +pst.stem(words))"]},{"cell_type":"code","execution_count":null,"id":"7e4b82e5","metadata":{"id":"7e4b82e5","outputId":"89006255-0921-4d05-95c6-6c86b44f425f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to C:\\Users\\Sirotul\n","[nltk_data]     Azhar\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["179"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n","\n","stopwords.words('english')\n","len(stopwords.words('english'))"]},{"cell_type":"code","execution_count":null,"id":"b8193139","metadata":{"id":"b8193139","outputId":"0104661d-3510-4a25-bf94-8784fe6b602a"},"outputs":[{"data":{"text/plain":["67"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","\n","punctuation = re.compile(r'[-.?!.:;()|0-9]')\n","post_punctuation=[]\n","for words in AI_tokens:\n","    word=punctuation.sub(\"\", 'words')\n","    if len(word) > 0:\n","       post_punctuation.append(word)\n","post_punctuation\n","len(post_punctuation)"]},{"cell_type":"code","execution_count":null,"id":"17b82ccc","metadata":{"id":"17b82ccc","executionInfo":{"status":"aborted","timestamp":1688395255139,"user_tz":-420,"elapsed":7,"user":{"displayName":"Rizky yanuar Kristianto","userId":"11223808917659739908"}}},"outputs":[],"source":["import pandas as pd\n","\n","data = pd.read_csv(\"data.csv\", encoding='latin-1')\n","data.head()"]},{"cell_type":"code","execution_count":1,"id":"402fa719","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"402fa719","executionInfo":{"status":"error","timestamp":1688395255137,"user_tz":-420,"elapsed":11,"user":{"displayName":"Rizky yanuar Kristianto","userId":"11223808917659739908"}},"outputId":"f97a60f7-a515-44a2-89c6-a7f8caddb09c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-020dcb2ea6a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}],"source":["data.Tweet[1]"]},{"cell_type":"code","execution_count":null,"id":"a0158aca","metadata":{"id":"a0158aca","outputId":"845ccd4b-0247-4768-d826-d2719797e5c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: Sastrawi in c:\\users\\sirotul azhar\\anaconda3\\envs\\nyoba\\lib\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n","\n"]}],"source":["pip install Sastrawi"]},{"cell_type":"code","execution_count":null,"id":"ec7c180e","metadata":{"id":"ec7c180e","outputId":"d0709b9b-7c80-44b5-980e-5dd3d14c0fe5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>original</th>\n","      <th>replacement</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>anakjakartaasikasik</td>\n","      <td>anak jakarta asyik asyik</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>pakcikdahtua</td>\n","      <td>pak cik sudah tua</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>pakcikmudalagi</td>\n","      <td>pak cik muda lagi</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>t3tapjokowi</td>\n","      <td>tetap jokowi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3x</td>\n","      <td>tiga kali</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              original               replacement\n","0  anakjakartaasikasik  anak jakarta asyik asyik\n","1         pakcikdahtua         pak cik sudah tua\n","2       pakcikmudalagi         pak cik muda lagi\n","3          t3tapjokowi              tetap jokowi\n","4                   3x                 tiga kali"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","alay_dict = pd.read_csv('new_kamusalay.csv', header=None, encoding='latin-1')\n","alay_dict = alay_dict.rename(columns={0: 'original',\n","                                     1: 'replacement'})\n","alay_dict.head()"]},{"cell_type":"code","execution_count":null,"id":"0950b867","metadata":{"id":"0950b867","outputId":"23533ffd-89a3-4a09-893c-543d821fb180"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stopword</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ada</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>adalah</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>adanya</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>adapun</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>agak</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  stopword\n","0      ada\n","1   adalah\n","2   adanya\n","3   adapun\n","4     agak"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["id_stopword_dict = pd.read_csv('stopwordbahasa.csv', header=None, encoding='latin-1')\n","id_stopword_dict = id_stopword_dict.rename(columns={0: 'stopword'})\n","id_stopword_dict.head()"]},{"cell_type":"code","execution_count":null,"id":"bc5a7852","metadata":{"id":"bc5a7852"},"outputs":[],"source":["import re\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","\n","factory = StemmerFactory()\n","stemmer = factory.create_stemmer()\n","\n","def lowercase(text):\n","    return text.lower()\n","\n","def remove_unnecessary_char(text):\n","    text = re.sub('\\n', ' ', text) # Remove every '\\n'\n","    text = re.sub('rt', ' ', text) # Remove every retweet symbol\n","    text = re.sub('user', ' ', text) # Remove every username\n","    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text) # Remove every url\n","    text = re.sub('  +', ' ', text) # Remove extra spaces\n","    return text\n","\n","def remove_nonaplhanumeric(text):\n","    text = re.sub ('[^0-9a-zA-Z]+', ' ', text)\n","    return text\n","\n","alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n","\n","def normalize_alay(text):\n","    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])"]},{"cell_type":"code","execution_count":null,"id":"31a03601","metadata":{"id":"31a03601"},"outputs":[],"source":["def remove_stopword(text):\n","    text = ' '.join([ ' ' if word in id_stopword_dict.stopword.values else word for word in text.split(' ')])\n","    text = re.sub('  +', ' ', text) # Remove extra spaces\n","    text = text.strip()\n","    return text\n","\n","def stemming (text):\n","    return stemmer.stem(text)\n"]},{"cell_type":"code","execution_count":null,"id":"ec10dbd4","metadata":{"id":"ec10dbd4"},"outputs":[],"source":["def preprocess(text):\n","    text = lowercase (text) # 1\n","    text = remove_nonaplhanumeric(text) #\n","    text = remove_unnecessary_char(text) #2\n","    text = normalize_alay (text) # 3 text stemming (text) # 4\n","    text = remove_stopword (text) # 5\n","    return text"]},{"cell_type":"code","execution_count":null,"id":"48494471","metadata":{"id":"48494471","outputId":"c3c1924f-e0c4-4f02-d737-da30b818f740"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>HS</th>\n","      <th>Abusive</th>\n","      <th>HS_Individual</th>\n","      <th>HS_Group</th>\n","      <th>HS_Religion</th>\n","      <th>HS_Race</th>\n","      <th>HS_Physical</th>\n","      <th>HS_Gender</th>\n","      <th>HS_Other</th>\n","      <th>HS_Weak</th>\n","      <th>HS_Moderate</th>\n","      <th>HS_Strong</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cowok berusaha melacak perhatian gue lantas re...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>telat tau edan sarap gue bergaul cigax jifla c...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41 kadang berpikir percaya tuhan jatuh berkali...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ku tau matamu sipit</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>kaum cebong kafir dongoknya dungu haha</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Tweet  HS  Abusive  \\\n","0  cowok berusaha melacak perhatian gue lantas re...   1        1   \n","1  telat tau edan sarap gue bergaul cigax jifla c...   0        1   \n","2  41 kadang berpikir percaya tuhan jatuh berkali...   0        0   \n","3                                ku tau matamu sipit   0        0   \n","4             kaum cebong kafir dongoknya dungu haha   1        1   \n","\n","   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n","0              1         0            0        0            0          0   \n","1              0         0            0        0            0          0   \n","2              0         0            0        0            0          0   \n","3              0         0            0        0            0          0   \n","4              0         1            1        0            0          0   \n","\n","   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n","0         1        1            0          0  \n","1         0        0            0          0  \n","2         0        0            0          0  \n","3         0        0            0          0  \n","4         0        0            1          0  "]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["data['Tweet'] = data['Tweet'].apply(preprocess)\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"7ed1d858","metadata":{"id":"7ed1d858","outputId":"c31b8d9c-324e-4646-fe6f-d5b2bade25f1"},"outputs":[{"ename":"NameError","evalue":"name 'processed_docs' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      3\u001b[0m count_vect \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[1;32m----> 5\u001b[0m bow_rep \u001b[38;5;241m=\u001b[39m count_vect\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mprocessed_docs\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur vocabulary: \u001b[39m\u001b[38;5;124m\"\u001b[39m, count_vect\u001b[38;5;241m.\u001b[39mvocabulary_)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoW representation for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog bites man\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m, bow_rep[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray())\n","\u001b[1;31mNameError\u001b[0m: name 'processed_docs' is not defined"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","count_vect = CountVectorizer()\n","\n","bow_rep = count_vect.fit_transform(processed_docs)\n","print(\"Our vocabulary: \", count_vect.vocabulary_)\n","\n","print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n","print(\"BoW representation for 'man bites dog': \", bow_rep[1].toarray())\n","\n","temp = count_vect.transform([\"dog and dog are friends\"])\n","\n","print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"]},{"cell_type":"code","execution_count":null,"id":"bf995254","metadata":{"id":"bf995254"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}