{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Kata kunci pencarian\n",
    "kata_kunci = input(\"Masukkan kata kunci: \")\n",
    "kata_kunci = kata_kunci.replace(' ', '+')\n",
    "\n",
    "sort_input = int(input('''pilih urutan berdasarkan\n",
    "ketik 1 untuk artikel yang relevan\n",
    "ketik 0 untuk artikel yang terbaru :\n",
    "'''))\n",
    "\n",
    "# Atur parameter urutan berdasarkan input pengguna\n",
    "sort = 'Relevance' if sort_input == 1 else 'PubDate'\n",
    "\n",
    "# Jumlah baris maksimum\n",
    "max_rows = int(input(\"Masukkan jumlah artikel yang dicari: \"))\n",
    "\n",
    "# Membuka file CSV\n",
    "with open('hasil_scraping.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Menulis header\n",
    "    writer.writerow([\"No\", \"Judul Artikel\", \"Nama Jurnal\", \"Prosiding\", \"Penulis\", \"Tahun Terbit\", \"URL Artikel\", \"URL PDF\", \"Abstrak\"])\n",
    "\n",
    "    # Inisialisasi nomor baris\n",
    "    row_number = 0\n",
    "\n",
    "    # Looping halaman\n",
    "    for page in range(1, max_rows):\n",
    "        # Jika jumlah baris maksimum telah tercapai, hentikan loop\n",
    "        if row_number >= max_rows:\n",
    "            break\n",
    "\n",
    "        # URL SpringerOpen\n",
    "        url = f\"https://www.springeropen.com/search?searchType=publisherSearch&sort={sort}&query={kata_kunci}&page={page}\"\n",
    "\n",
    "        # Membuat permintaan ke SpringerOpen\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Mencari semua elemen dengan class 'c-list-group__item'\n",
    "        results = soup.find_all('li', {'class': 'c-listing__item u-keyline'})\n",
    "\n",
    "        # Looping melalui setiap hasil dan mengekstrak informasi\n",
    "        for result in results:\n",
    "            # Tambahkan nomor baris\n",
    "            row_number += 1\n",
    "\n",
    "            # Jika jumlah baris maksimum telah tercapai, hentikan loop\n",
    "            if row_number > max_rows:\n",
    "                break\n",
    "\n",
    "            title = result.find('h3', {'class': 'c-listing__title'}).text if result.find('h3', {'class': 'c-listing__title'}) else \"N/A\"\n",
    "            journal_info = result.find('em',{'data-test': 'journal-title'}).text if result.find('em',{'data-test': 'journal-title'}) else \"N/A\"\n",
    "            url_article_element = result.find('a')\n",
    "            url_article = \"https:\" + url_article_element['href'] if url_article_element and url_article_element.has_attr('href') else \"N/A\"\n",
    "\n",
    "            author = result.find('span', {'class': 'c-listing__authors-list'}).text if result.find('span', {'class': 'c-listing__authors-list'}) else \"N/A\"\n",
    "            year_published = result.find('span', {'itemprop': 'datePublished'}).text if result.find('span', {'itemprop': 'datePublished'}) else \"N/A\"\n",
    "\n",
    "            pdf_link_element = result.find('a', {'data-test': 'pdf-link'})\n",
    "\n",
    "            pdf_link = \"https:\" + pdf_link_element['href'] if pdf_link_element and pdf_link_element.has_attr('href') else \"N/A\"\n",
    "\n",
    "            # Membuat permintaan ke halaman artikel\n",
    "            url_abstract_element = result.find('a', itemprop='url')\n",
    "            abstract_link = \"https:\" + url_abstract_element['href']\n",
    "            article_response = requests.get(abstract_link)\n",
    "            article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
    "\n",
    "            # Temukan div dengan class 'c-article-section__content'\n",
    "            result_abstract = article_soup.find('div', {'class': 'c-article-section__content'})\n",
    "\n",
    "            # Ekstrak teks dalam tag <p> di dalam div\n",
    "            abstract = result_abstract.find('p').text if result_abstract and result_abstract.find('p') else \"N/A\"\n",
    "\n",
    "            # Mengubah abstrak menjadi teks biasa (ASCII)\n",
    "            abstract_plain = abstract.encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "            # Menghapus spasi ekstra\n",
    "            abstract_plain = \" \".join(abstract_plain.split())\n",
    "\n",
    "            # Menulis baris ke file CSV\n",
    "            writer.writerow([row_number, title, journal_info, \"N/A\", author, year_published, url_article, pdf_link, abstract_plain])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
